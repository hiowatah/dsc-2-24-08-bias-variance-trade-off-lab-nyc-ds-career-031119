{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-Variance Trade-Off - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll practice your knowledge on the bias-variance trade-off!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to: \n",
    "- Look at an example where Polynomial regression leads to overfitting\n",
    "- Understand how bias-variance trade-off relates to underfitting and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try to predict some movie revenues based on certain factors, such as ratings and movie year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>domgross</th>\n",
       "      <th>title</th>\n",
       "      <th>Response_Json</th>\n",
       "      <th>Year</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>Metascore</th>\n",
       "      <th>imdbVotes</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13000000</td>\n",
       "      <td>25682380</td>\n",
       "      <td>21 &amp;amp; Over</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>6.8</td>\n",
       "      <td>48</td>\n",
       "      <td>206513</td>\n",
       "      <td>4.912759e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45658735</td>\n",
       "      <td>13414714</td>\n",
       "      <td>Dredd 3D</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.267265e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000000</td>\n",
       "      <td>53107035</td>\n",
       "      <td>12 Years a Slave</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.1</td>\n",
       "      <td>96</td>\n",
       "      <td>537525</td>\n",
       "      <td>1.626624e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61000000</td>\n",
       "      <td>75612460</td>\n",
       "      <td>2 Guns</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>6.7</td>\n",
       "      <td>55</td>\n",
       "      <td>173726</td>\n",
       "      <td>7.723381e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40000000</td>\n",
       "      <td>95020213</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>7.5</td>\n",
       "      <td>62</td>\n",
       "      <td>74170</td>\n",
       "      <td>4.151958e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     budget  domgross             title  Response_Json  Year  imdbRating  \\\n",
       "0  13000000  25682380     21 &amp; Over              0  2008         6.8   \n",
       "1  45658735  13414714          Dredd 3D              0  2012         0.0   \n",
       "2  20000000  53107035  12 Years a Slave              0  2013         8.1   \n",
       "3  61000000  75612460            2 Guns              0  2013         6.7   \n",
       "4  40000000  95020213                42              0  2013         7.5   \n",
       "\n",
       "   Metascore  imdbVotes         Model  \n",
       "0         48     206513  4.912759e+07  \n",
       "1          0          0  2.267265e+05  \n",
       "2         96     537525  1.626624e+08  \n",
       "3         55     173726  7.723381e+07  \n",
       "4         62      74170  4.151958e+07  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_excel('./movie_data_detailed_with_ols.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domgross</th>\n",
       "      <th>budget</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>Metascore</th>\n",
       "      <th>imdbVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055325</td>\n",
       "      <td>0.034169</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.384192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023779</td>\n",
       "      <td>0.182956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.125847</td>\n",
       "      <td>0.066059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183719</td>\n",
       "      <td>0.252847</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.323196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.233625</td>\n",
       "      <td>0.157175</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.137984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   domgross    budget  imdbRating  Metascore  imdbVotes\n",
       "0  0.055325  0.034169    0.839506   0.500000   0.384192\n",
       "1  0.023779  0.182956    0.000000   0.000000   0.000000\n",
       "2  0.125847  0.066059    1.000000   1.000000   1.000000\n",
       "3  0.183719  0.252847    0.827160   0.572917   0.323196\n",
       "4  0.233625  0.157175    0.925926   0.645833   0.137984"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keep four predictors and transform the with MinMaxScaler\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "df = df[[ \"domgross\", \"budget\", \"imdbRating\", \"Metascore\", \"imdbVotes\"]]\n",
    "transformed = scale.fit_transform(df)\n",
    "pd_df = pd.DataFrame(transformed, columns = df.columns)\n",
    "pd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into a test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# domgross is the outcome variable\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "X = pd_df[['budget','imdbRating','Metascore','imdbVotes']]\n",
    "y = pd_df['domgross']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a regression model to the training data and look at the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code \n",
    "from sklearn.linear_model import *\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84624072, 0.01204488, 0.15068256, 0.20692101])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the training predictions against the actual data (y_hat_train vs. y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our result for the train data. Because we have multiple predictors, we can not simply plot the income variable X on the x-axis and target y on the y-axis. Lets plot \n",
    "- a line showing the diagonal of y_train. The actual y_train values are on this line\n",
    "- next, make a scatter plot that takes the actual y_train on the x-axis and the predictions using the model on the y-axis. You will see points scattered around the line. The horizontal distances between the points and the lines are the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-42e429a1eb81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Actual Data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model vs Data for Training Set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(y_train, linreg.predict(X_train), label='Model')\n",
    "plt.plot(x_train, y_train, label='Actual Data')\n",
    "plt.title('Model vs Data for Training Set')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the test predictions against the actual data (y_hat_test vs. y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same thing for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the bias\n",
    "Write a formula to calculate the bias of a models predictions given the actual data: $Bias(\\hat{f}(x)) = E[\\hat{f}(x)-f(x)]$   \n",
    "(The expected value can simply be taken as the mean or average value.)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def bias(y, y_hat):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the variance\n",
    "Write a formula to calculate the variance of a model's predictions: $Var(\\hat{f}(x)) = E[\\hat{f}(x)^2] - \\big(E[\\hat{f}(x)]\\big)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(y_hat):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use your functions to calculate the bias and variance of your model. Do this seperately for the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for train set bias and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for test set bias and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe in words what these numbers can tell you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your description here (this cell is formatted using markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit a new model by creating additional features by raising current features to various powers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `PolynomialFeatures` with degree 3. \n",
    "\n",
    "**Important note:** By including this, you don't only take polynomials of single variables, but you also combine variables, eg:\n",
    "\n",
    "$ \\text{Budget} * \\text{MetaScore} ^ 2 $\n",
    "\n",
    "What you're essentially doing is taking interactions and creating polynomials at the same time! Have a look at how many columns we get using `np.shape`. Quite a few!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\\\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot your overfitted model's training predictions against the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, we almost get a perfect fit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the bias and variance for the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot your overfitted model's test predictions against the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Calculate the bias and variance for the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe what you notice about the bias and variance statistics for your overfit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bias and variance for the test set both increased drastically in the overfit model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up - Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we went from 4 predictors to 35 by adding polynomials and interactions, using `PolynomialFeatures`. That being said, where 35 leads to overfitting, there are probably ways to improve by just adding a few polynomials. Feel free to experiment and see how bias and variance improve!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab gave you insight in how bias and variance change for a training and test set by using a pretty \"simple\" model, and a very complex model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
